{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from lib.computational_graph_approach.layers import *\n",
    "from lib.computational_graph_approach.utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "MNIST_MEAN = 0.1307\n",
    "MNIST_STDEV = 0.3081\n",
    "\n",
    "def get_mnist(get_train_set):\n",
    "  return torchvision.datasets.MNIST(\n",
    "      root=\"data\",\n",
    "      train=get_train_set,\n",
    "      download=True,\n",
    "      # For demonstration\n",
    "      transform=torchvision.transforms.Compose([\n",
    "          torchvision.transforms.ToTensor(),\n",
    "          torchvision.transforms.Normalize((MNIST_MEAN,), (MNIST_STDEV,))\n",
    "      ])\n",
    "  )\n",
    "\n",
    "trn_set = get_mnist(get_train_set=True)\n",
    "val_set = get_mnist(get_train_set=False)  # Technically the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(Network):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers = [\n",
    "            FC_faster(28*28, 5, \"relu\"),\n",
    "            FC_faster(5, 10)\n",
    "        ]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        output = []\n",
    "        # inputs = cp.asarray(inputs)\n",
    "        inputs = inputs.reshape(-1, 28*28)\n",
    "        for input in inputs:\n",
    "            x = self.layers[0](input)\n",
    "            x = self.layers[1](x)\n",
    "            output.append(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data formatting\n",
    "NUM_DATA = 1000\n",
    "trn_set_np = []\n",
    "trn_set_np_labels = []\n",
    "for d in range(NUM_DATA):\n",
    "    trn_set_np.append(np.array(trn_set[d][0][0]))\n",
    "    trn_set_np_labels.append(np.array(trn_set[d][1]))\n",
    "trn_set_np = np.array(trn_set_np)\n",
    "trn_set_np_labels = np.array(trn_set_np_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(outputs, labels):\n",
    "    loss = 0\n",
    "    for out, l in zip(outputs, labels):\n",
    "        numerator = np.sum([np.e ** o for o in out])\n",
    "        denominator = np.e ** out[l]\n",
    "        loss += (numerator/denominator).log()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6040589809417725, 0.574599027633667, 0.532639741897583, 0.7438745498657227, 0.5712816715240479, 0.594357967376709, 0.5847818851470947, 0.5714931488037109, 0.5440363883972168, 0.7349283695220947, 0.5636448860168457, 0.5640311241149902, 0.7457664012908936, 0.5789430141448975, 0.5840668678283691, 0.5764491558074951, 0.5505998134613037, 0.7159466743469238, 0.5588610172271729, 0.7578215599060059, 0.5821490287780762, 0.5800528526306152, 0.5513007640838623, 0.7262320518493652, 0.5630800724029541]\n",
      "Forward pass: 610.20 ms\n",
      "[]\n",
      "Backward pass: nan ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujay/miniconda3/envs/567-final-project/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/sujay/miniconda3/envs/567-final-project/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "nn = NN()\n",
    "timer = Timer()\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "forwards = []\n",
    "backwards = []\n",
    "\n",
    "batch_data = np.split(trn_set_np, int(len(trn_set_np) / BATCH_SIZE))\n",
    "batch_labels = np.split(trn_set_np_labels, int(len(trn_set_np) / BATCH_SIZE))\n",
    "timer.start()\n",
    "for d, l in zip(batch_data, batch_labels):\n",
    "    # nn.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    timer.start()\n",
    "    outputs = nn(d)\n",
    "    # loss = cross_entropy_loss(outputs, l)\n",
    "    forwards.append(timer.stop())\n",
    "\n",
    "    # Backward pass\n",
    "    # timer.start()\n",
    "    # loss.backward()\n",
    "    # backwards.append(timer.stop())\n",
    "\n",
    "print(forwards)\n",
    "print(\"Forward pass: {:.2f} ms\".format(np.mean(np.array(forwards)) * 1000))\n",
    "print(backwards)\n",
    "print(\"Backward pass: {:.2f} ms\".format(np.mean(np.array(backwards)) * 1000))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
